{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import feature_selection\n",
    "from numpy import dot, zeros\n",
    "from numpy.linalg import matrix_rank, norm\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Critere de performance\n",
    "def compute_pred_score(y_true, y_pred):\n",
    "    y_comp = y_true * y_pred\n",
    "    score = float(10*np.sum(y_comp == -1) + np.sum(y_comp == 0))\n",
    "    score /= y_comp.shape[0]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_fname = 'training_templates.csv'\n",
    "y_train_fname = 'training_labels.txt'\n",
    "X_test_fname  = 'testing_templates.csv'\n",
    "X_train = pd.DataFrame(pd.read_csv(X_train_fname, sep=',', header=None))\n",
    "X_test  = pd.DataFrame(pd.read_csv(X_test_fname,  sep=',', header=None).values)\n",
    "y_train = np.loadtxt(y_train_fname, dtype=np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord regardons si les colonnes sont *correlées* entre elles, auquel cas on poura enlever celles qui le sont trop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set(context=\"paper\", font=\"monospace\")\n",
    "corrmat = X_test.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True, xticklabels=False, yticklabels=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visiblement, aucune corrélation évidente n'apparait."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etudions la distribution des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.hist(figsize=(50,50));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables suivent toutes des lois normales, il n'y a pas de problèmes évidents sur ces densités (distribution anormale, valeurs manquantes ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va se donner une référence avec un modèle de base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = linear_model.LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred_train =  clf.predict(X_train)\n",
    "\n",
    "# Compute the score\n",
    "score = compute_pred_score(y_train, y_pred_train)\n",
    "print('Score sur le train : %s' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant étudier les différentes *features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimator = linear_model.LogisticRegression()\n",
    "selector = RFECV(estimator, step=1, cv=5)\n",
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(selector.support_) \n",
    "print(selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.where(selector.support_ == False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'aprés cette sélection on voit que les colonnes #0, #10, #17, #18, #28, #72, #80, #104 et #117 ne sont pas significatives pour la régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.drop([  0,  10,  17,  18,  28,  72,  80, 104, 117], axis=1, inplace= True)\n",
    "X_train.drop([  0,  10,  17,  18,  28,  72,  80, 104, 117],axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X_test.shape, X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Est-ce que le retrait de ces colonnes améliore le score ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "# Prediction\n",
    "y_pred_train =  clf.predict(X_train)\n",
    "\n",
    "# Compute the score\n",
    "score = compute_pred_score(y_train, y_pred_train)\n",
    "print('Score sur le train : %s' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y'a une légère amélioration du score.\n",
    "Prennons ce classifieur comme notre base de référence.\n",
    "Sur le leaderboard le score n'est pas interessant.\n",
    "La classification concerne le traitement d'image, nous savons que sur ce type de problématique, les réseaux de neurones sont performants. Nous allons dorénavant exploiter la classe MLP de sklearn et faire notre sélection de variables en ce sens. Nous allons reprendre le dataset d'origine puisque la feature selection a été faite pour une régression logistique mais n'est pas possible pour un réseau de neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(pd.read_csv(X_train_fname, sep=',', header=None))\n",
    "X_test  = pd.DataFrame(pd.read_csv(X_test_fname,  sep=',', header=None).values)\n",
    "clf2 = MLPClassifier()\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred_train =  clf2.predict(X_train)\n",
    "\n",
    "# Compute the score\n",
    "score = compute_pred_score(y_train, y_pred_train)\n",
    "print('Score sur le train : %s' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score est déjà plus intéressant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = clf2.predict(X_test)\n",
    "np.savetxt('y_pred.txt', y_pred, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Sur le leaderboard nous obtenons un score de **0.35**\n",
    "Est-ce que la standardization améliore le score ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred_train =  clf2.predict(X_train)\n",
    "\n",
    "# Compute the score\n",
    "score = compute_pred_score(y_train, y_pred_train)\n",
    "print('Score sur le train : %s' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur les données d'entrainement le score se dégrade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf2.predict(X_test)\n",
    "np.savetxt('y_pred.txt', y_pred, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La même dégradation se constate sur le leaderboard avec un score de **0.40**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant nous allons rechercher les hyper paramètres optimaux via un grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rechargeons nos données sans Standardization\n",
    "X_train = pd.DataFrame(pd.read_csv(X_train_fname, sep=',', header=None))\n",
    "X_test  = pd.DataFrame(pd.read_csv(X_test_fname,  sep=',', header=None).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf2 = MLPClassifier(max_iter=100, solver='adam', hidden_layer_sizes=14, activation='tanh', alpha = 0.0002)\n",
    "#param_grid = { 'max_iter' : [100, 300, 500, 1000]}\n",
    "#grid_search = GridSearchCV(clf2, param_grid=param_grid)\n",
    "#start = time()\n",
    "#grid_search.fit(X_train, y_train)\n",
    "\n",
    "#print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "#      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "#report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que l'on a optimisé les hyper-paramètres on va prédire sur les données de test pour voir si la performance c'est améliorée.\n",
    "Le score obtenu est moins bon que le précédent **0.3438**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf2 = MLPClassifier(solver='adam', hidden_layer_sizes=14, activation='tanh', alpha = 0.0002, max_iter=300)\n",
    "# Prediction\n",
    "clf2.fit(X_train, y_train)\n",
    "y_pred_train =  clf2.predict(X_train)\n",
    "# Compute the score\n",
    "score = compute_pred_score(y_train, y_pred_train)\n",
    "print('Score sur le train : %s' % score)\n",
    "y_pred = clf2.predict(X_test)\n",
    "np.savetxt('y_pred.txt', y_pred, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Revenons au MLP, nous allons chercher les meilleurs hyper-paramètres et affiner notre décision sur le critère de la probabilité de prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_learn, x_val, y_learn, y_val =  train_test_split(X_train, y_train, train_size = 0.5, test_size=0.5)\n",
    "clf3 = MLPClassifier(random_state=79,shuffle=True)\n",
    "\n",
    "alphas = np.logspace(-5, -1 ) \n",
    "# Première GridSearch :  param_grid = { 'hidden_layer_sizes' : range(100,210,10), 'alpha':np.logspace(-5, -1 )} \n",
    "# Résultat : hidden layer sizes : 170 et alpha = 0.01264855117962958\n",
    "# Seconde param_grid = { 'hidden_layer_sizes' : range(160,180,10), 'alpha':np.linspace(0.01, 0.02, 20)} \n",
    "# Résultat {'alpha': 0.014444444444444444, 'hidden_layer_sizes': 168}\n",
    "param_grid = { 'hidden_layer_sizes' : range(165,175,1), 'alpha':np.linspace(0.01, 0.02, 10)} \n",
    "grid_search = GridSearchCV(clf3, param_grid=param_grid, verbose=10, n_jobs=-1)\n",
    "start = time()\n",
    "grid_search.fit(x_learn, y_learn)\n",
    "print(grid_search.best_params_) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf3 = MLPClassifier(random_state=33,shuffle=True,\n",
    "                     hidden_layer_sizes=[168,2], alpha=0.014444)\n",
    "clf3.fit(x_learn,y_learn)\n",
    "y_pred_train =  clf3.predict(x_val)\n",
    "score = compute_pred_score(y_pred_train, y_val)\n",
    "print('Score sur la validation : %s' % score) #0.1861742\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proba_class_neg = np.transpose(clf3.predict_proba(X_test))[0]\n",
    "n, bins, patches = plt.hist(proba_class_neg, 10, facecolor = 'red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proba_class_pos = np.transpose(clf3.predict_proba(X_test))[1]\n",
    "npos, binspos, patchespos = plt.hist(proba_class_pos, 10, facecolor = 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "undefined = np.transpose(np.where(np.logical_and(0.1 < proba_class_neg, proba_class_neg < 0.90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred[undefined] = 0\n",
    "print(len(y_pred[undefined]))\n",
    "print(len(y_pred[y_pred == -1]))\n",
    "print(len(y_pred[y_pred == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('y_pred.txt', y_pred, fmt='%d')#  0.156544256121 sur le leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour améliorer le score on va essayer de classifier les prédictions à 0 avec un autre classifieur. \n",
    "Pour ce faire nous allons trouver les données d'entrainement qui correspondent le plus aux données de test non classifiées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "indexes = y_pred == 0\n",
    "dist_argmin = pairwise_distances_argmin(X_test[indexes], X_train)\n",
    "X_train_reclass = X_train.iloc[dist_argmin][:int(0.1 * len(X_train))]\n",
    "y_train_reclass = y_train[dist_argmin][:int(0.1 * len(y_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Faisons une GridSearch avec un SVC et 80 % des données d'entrainement ressamblant le plus au données de test mal \n",
    "# classifiées\n",
    "x_learn, x_val, y_learn, y_val =  train_test_split(X_train_reclass, y_train_reclass, train_size = 0.8)\n",
    "svc = SVC()\n",
    "param_grid = { 'C' : np.linspace(1.5,2.5,20), 'gamma': np.linspace(0.7,2,100), 'kernel' : ['rbf']}\n",
    "grid_search = GridSearchCV(svc, param_grid=param_grid, verbose=10, n_jobs=-1)\n",
    "# 1er grid search {'gamma': 0.77426368268112777, C': 2.1544346900318834, 'kernel': 'rbf'}\n",
    "# 2e {'gamma': 0.88775510204081631, 'kernel': 'rbf', 'C': 2.333333333333333}\n",
    "# 3e {'gamma': 0.88979591836734695, 'kernel': 'rbf', 'C': 2.3333333333333335}\n",
    "# 4e {'gamma': 0.88888888888888895, 'kernel': 'rbf', 'C': 2.4777777777777779}\n",
    "# Leadeboard : 0.23\n",
    "# On augmente la confiance accordée au classifieur réseau de neurones en prennant seulement 707 points non classifiés \n",
    "# 1er grid search {'gamma': 0.89000000000000001, 'kernel': 'rbf', 'C': 2.5}\n",
    "# 2e {'gamma': 1.1666666666666665, 'kernel': 'rbf', 'C': 2.0}\n",
    "# 3e {'gamma': 0.89696969696969697, 'kernel': 'rbf', 'C': 2.236842105263158}\n",
    "start = time()\n",
    "grid_search.fit(x_learn, y_learn)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc = SVC(gamma = 0.89, kernel='rbf', C = 2.2368)\n",
    "svc.fit(x_learn,y_learn)\n",
    "y_pred_train =  svc.predict(x_val)\n",
    "score = compute_pred_score(y_pred_train, y_val)\n",
    "print('Score sur la validation : %s' % score) #0.1861742 et 0.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.fit(X_train_reclass, y_train_reclass)\n",
    "y_pred_reclass = svc.predict(X_test[indexes])\n",
    "y_pred[indexes] = y_pred_reclass\n",
    "np.savetxt('y_pred.txt', y_pred, fmt='%d')#  0.24 puis 0.27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refaisons la démarche avec un autre réseau de neurone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Faisons une GridSearch avec un MLP et 80 % des données d'entrainement ressamblant le plus au données de test mal \n",
    "# classifiées\n",
    "x_learn, x_val, y_learn, y_val =  train_test_split(X_train_reclass, y_train_reclass, train_size = 0.8)\n",
    "mlpReclass = MLPClassifier()\n",
    "layers =[(100,2),(110,2),(120,2),(130,2),(140,2),(150,2),(160,2),(170,2),(200,2)]\n",
    "param_grid =  {'hidden_layer_sizes' : layers, 'alpha':np.logspace(-5, -1, 20)}\n",
    "grid_search = GridSearchCV(mlpReclass, param_grid=param_grid, verbose=10, n_jobs=-1)\n",
    "#{'hidden_layer_sizes': 130, 'alpha': 0.038421052631578953}\n",
    "# 2e {'alpha': 1.6237767391887208e-05, 'hidden_layer_sizes': (160, 3)}\n",
    "start = time()\n",
    "grid_search.fit(x_learn, y_learn)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlpReclass = MLPClassifier(hidden_layer_sizes = 130, alpha = 0.038421052631578953)\n",
    "mlpReclass.fit(x_learn,y_learn)\n",
    "y_pred_train =  mlpReclass.predict(x_val)\n",
    "score = compute_pred_score(y_pred_train, y_val)\n",
    "print('Score sur la validation : %s' % score) #0.845"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proba_class_neg = np.transpose(mlpReclass.predict_proba(x_val))[0]\n",
    "n, bins, patches = plt.hist(proba_class_neg, 10, facecolor = 'red')\n",
    "proba_class_pos = np.transpose(mlpReclass.predict_proba(x_val))[1]\n",
    "n, bins, patches = plt.hist(proba_class_pos, 10, facecolor = 'blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "undefined_reclass = np.transpose(np.where(np.logical_and(0. < proba_class_neg, proba_class_neg < 0.95))) \n",
    "#0.1 et 0.9 = 0.1833 0.05 et 0.95 = 0.184792843691\n",
    "y_pred[undefined_reclass] = 0\n",
    "print(len(y_pred[undefined_reclass]))\n",
    "print(len(y_pred[y_pred == -1]))\n",
    "print(len(y_pred[y_pred == 1]))\n",
    "np.savetxt('y_pred.txt', y_pred, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_learn, x_val, y_learn, y_val =  train_test_split(X_train, y_train, train_size = 0.1)\n",
    "ks = range(3,8,1)\n",
    "leaves = range(25,45, 5)\n",
    "ps= range(1,3, 1)\n",
    "weights = ['uniform','distance']\n",
    "knn = KNeighborsClassifier(n_jobs=-1, algorithm='ball_tree')\n",
    "param_grid = { 'leaf_size' : leaves, 'n_neighbors': ks,\n",
    "             'p':ps,'weights' : weights}\n",
    "grid_search = GridSearchCV(knn, param_grid=param_grid, verbose=10, n_jobs=-1)\n",
    "start = time()\n",
    "grid_search.fit(x_learn, y_learn)\n",
    "print(grid_search.best_params_) # {'n_neighbors': 6, 'weights': 'distance', 'p': 2, 'leaf_size': 25}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Généralisons l'approche en repartant du dataset d'entrainement initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist_argmin = pairwise_distances_argmin(X_test, X_train)\n",
    "X_train_reclass = X_train.iloc[dist_argmin][:len(X_train * 0.1)]\n",
    "y_train_reclass = y_train[dist_argmin][:len(X_train * 0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_learn, x_val, y_learn, y_val =  train_test_split(X_train_reclass, y_train_reclass, train_size = 0.2)\n",
    "mlpPairwise = MLPClassifier(hidden_layer_sizes=170, activation='relu', solver = 'adam')\n",
    "param_grid =  {'beta_1': np.linspace(0.25,0.5,5), 'beta_2': np.linspace(0.996,0.999,5),\n",
    "               'alpha': np.linspace(0.0002,0.0004, 5)}\n",
    "grid_search = GridSearchCV(mlpPairwise, param_grid=param_grid, verbose=10, n_jobs=-1)\n",
    "# 1 :{'beta_2': 0.99770006382255327, 'alpha': 0.00031622776601683794, 'beta_1': 0.31586390484234717}\n",
    "# 2 : adam\n",
    "# 3 beta1, beta2 : nothing\n",
    "# 4 {'beta_2': 0.99750000000000005, 'alpha': 0.00020000000000000001, 'beta_1': 0.375}\n",
    "start = time()\n",
    "grid_search.fit(x_learn, y_learn)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_learn, x_val, y_learn, y_val =  train_test_split(X_train_reclass, y_train_reclass, train_size = 0.8)\n",
    "mlpPairwise = MLPClassifier(hidden_layer_sizes=170, activation='relu', solver = 'adam',\n",
    "                            beta_1=0.375, beta_2=0.9975, alpha = 0.0002)\n",
    "mlpPairwise.fit(x_learn, y_learn)\n",
    "y_pred_train =  mlpPairwise.predict(x_val)\n",
    "score = compute_pred_score(y_pred_train, y_val)\n",
    "print('Score sur la validation : %s' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlpPairwise.fit(X_train_reclass, y_train_reclass)\n",
    "y_pred = mlpPairwise.predict(X_test)\n",
    "proba_class_neg = np.transpose(mlpPairwise.predict_proba(X_test))[0]\n",
    "proba_class_pos = np.transpose(mlpPairwise.predict_proba(X_test))[1]\n",
    "y_pred[undefined_reclass] = 0\n",
    "np.savetxt('y_pred.txt', y_pred, fmt='%d')#0.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_learn, x_val, y_learn, y_val =  train_test_split(X_train_reclass, y_train_reclass, train_size = 0.3)\n",
    "svc = SVC(kernel = 'rbf')\n",
    "param_grid = { 'C' : np.linspace(2.5,2.8,20), 'gamma': np.linspace(0.6,0.7,10)}\n",
    "grid_search = GridSearchCV(svc, param_grid=param_grid, verbose=10, n_jobs=-1)\n",
    "# 1 {'gamma': 0.66666666666666663, 'kernel': 'rbf', 'C': 2.6366508987303581}\n",
    "# 2 {'gamma': 0.65555555555555556, 'C': 2.5}\n",
    "start = time()\n",
    "grid_search.fit(x_learn, y_learn)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_learn, x_val, y_learn, y_val =  train_test_split(X_train_reclass, y_train_reclass, train_size = 0.88)\n",
    "\n",
    "svc = SVC(kernel = 'rbf', gamma=0.656, C = 2.5)\n",
    "svc.fit(X_train_reclass, y_train_reclass)\n",
    "y_pred_train =  svc.predict(x_val)\n",
    "score = compute_pred_score(y_pred_train, y_val)\n",
    "print('Score sur la validation : %s' % score)\n",
    "y_pred = svc.predict(X_test)\n",
    "np.savetxt('y_pred.txt', y_pred, fmt='%d')#0.1977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_learn, x_val, y_learn, y_val =  train_test_split(X_train_reclass, y_train_reclass, train_size = 0.5)\n",
    "\n",
    "knn = KNeighborsClassifier(n_jobs=-1, algorithm='ball_tree', weights='distance')\n",
    "param_grid = { 'leaf_size' : range(1,10,1), 'n_neighbors': range(3,6,1),'p': [1,2]}\n",
    "grid_search = GridSearchCV(knn, param_grid=param_grid, verbose=10, n_jobs=-1)\n",
    "start = time()\n",
    "grid_search.fit(x_learn, y_learn)\n",
    "print(grid_search.best_params_) # {'n_neighbors': 6, 'weights': 'distance', 'p': 2, 'leaf_size': 25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn =KNeighborsClassifier(n_neighbors=6, p=2, leaf_size=25)\n",
    "knn.fit(X_train_reclass, y_train_reclass)\n",
    "y_pred_train =  knn.predict(x_val)\n",
    "score = compute_pred_score(y_pred_train, y_val)\n",
    "print('Score sur la validation : %s' % score)\n",
    "y_pred = knn.predict(X_test)\n",
    "np.savetxt('y_pred.txt', y_pred, fmt='%d')#0.1977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
